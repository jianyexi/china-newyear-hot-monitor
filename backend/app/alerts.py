"""
å‘Šè­¦é€šçŸ¥ç³»ç»Ÿ
- çªå‘çƒ­ç‚¹æ£€æµ‹ï¼ˆçƒ­åº¦çªå¢ï¼‰
- å…³é”®è¯å‘Šè­¦
- çˆ¬è™«æ•…éšœå‘Šè­¦
- Webhook æ¨é€ï¼ˆä¼ä¸šå¾®ä¿¡/é’‰é’‰/è‡ªå®šä¹‰ï¼‰
"""

import json
import logging
import datetime

import httpx

from app.schemas import HotTopicOut

logger = logging.getLogger(__name__)


async def send_webhook(url: str, title: str, content: str) -> bool:
    """å‘é€ Webhook é€šçŸ¥ï¼Œè‡ªåŠ¨æ£€æµ‹ä¼ä¸šå¾®ä¿¡/é’‰é’‰/é€šç”¨æ ¼å¼"""
    if not url:
        return False
    try:
        if "qyapi.weixin" in url:
            # ä¼ä¸šå¾®ä¿¡
            payload = {
                "msgtype": "markdown",
                "markdown": {"content": f"## {title}\n{content}"},
            }
        elif "oapi.dingtalk" in url:
            # é’‰é’‰
            payload = {
                "msgtype": "markdown",
                "markdown": {"title": title, "text": f"## {title}\n{content}"},
            }
        else:
            # é€šç”¨ webhook
            payload = {"title": title, "content": content, "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat()}

        async with httpx.AsyncClient(timeout=10) as client:
            resp = await client.post(url, json=payload)
            resp.raise_for_status()
            logger.info("Webhook sent: %s", title)
            return True
    except Exception as e:
        logger.warning("Webhook failed (%s): %s", url[:50], e)
        return False


def detect_spikes(
    current_topics: list[HotTopicOut],
    previous_topics: list[HotTopicOut],
    threshold: float = 2.0,
) -> list[dict]:
    """æ£€æµ‹çƒ­åº¦çªå¢çš„è¯é¢˜ (å½“å‰çƒ­åº¦ > ä¸Šè½®çƒ­åº¦ * threshold)"""
    prev_map: dict[str, int] = {}
    for t in previous_topics:
        key = f"{t.platform}:{t.title}"
        prev_map[key] = t.hot_value or 0

    spikes = []
    for t in current_topics:
        key = f"{t.platform}:{t.title}"
        current_val = t.hot_value or 0
        prev_val = prev_map.get(key, 0)

        if prev_val > 0 and current_val > prev_val * threshold:
            spikes.append({
                "platform": t.platform,
                "title": t.title,
                "previous_value": prev_val,
                "current_value": current_val,
                "increase_ratio": round(current_val / prev_val, 2),
            })
        elif prev_val == 0 and t.rank <= 3:
            # æ–°ä¸Šæ¦œ Top3
            spikes.append({
                "platform": t.platform,
                "title": t.title,
                "previous_value": 0,
                "current_value": current_val,
                "increase_ratio": 0,
                "note": "æ–°ä¸Šæ¦œ Top3",
            })

    return sorted(spikes, key=lambda x: x.get("increase_ratio", 0), reverse=True)


def check_keyword_alerts(
    topics: list[HotTopicOut],
    alert_keywords: list[str],
) -> list[dict]:
    """æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…å‘Šè­¦å…³é”®è¯çš„è¯é¢˜"""
    matches = []
    for t in topics:
        for kw in alert_keywords:
            if kw in t.title:
                matches.append({
                    "keyword": kw,
                    "platform": t.platform,
                    "title": t.title,
                    "rank": t.rank,
                })
    return matches


async def process_alerts(
    current_topics: list[HotTopicOut],
    previous_topics: list[HotTopicOut],
    scrape_errors: dict[str, str],
    alert_rules: list[dict],
) -> list[dict]:
    """å¤„ç†æ‰€æœ‰å‘Šè­¦è§„åˆ™ï¼Œå‘é€é€šçŸ¥"""
    triggered: list[dict] = []

    for rule in alert_rules:
        if not rule.get("enabled", True):
            continue

        rule_type = rule.get("rule_type", "")
        config = json.loads(rule.get("config_json", "{}") or "{}")
        webhook_url = rule.get("webhook_url", "")

        if rule_type == "spike":
            threshold = config.get("threshold", 2.0)
            spikes = detect_spikes(current_topics, previous_topics, threshold)
            if spikes:
                content_lines = [f"- **{s['platform']}** [{s['title']}] çƒ­åº¦ {s.get('previous_value',0)} â†’ {s['current_value']}" for s in spikes[:5]]
                await send_webhook(webhook_url, "ğŸ”¥ çƒ­åº¦çªå¢å‘Šè­¦", "\n".join(content_lines))
                triggered.append({"rule": rule["name"], "type": "spike", "count": len(spikes), "items": spikes[:5]})

        elif rule_type == "keyword":
            keywords = config.get("keywords", [])
            matches = check_keyword_alerts(current_topics, keywords)
            if matches:
                content_lines = [f"- [{m['keyword']}] {m['platform']} #{m['rank']} {m['title']}" for m in matches[:5]]
                await send_webhook(webhook_url, "ğŸ”” å…³é”®è¯å‘Šè­¦", "\n".join(content_lines))
                triggered.append({"rule": rule["name"], "type": "keyword", "count": len(matches), "items": matches[:5]})

        elif rule_type == "failure":
            if scrape_errors:
                content_lines = [f"- **{p}**: {err}" for p, err in scrape_errors.items()]
                await send_webhook(webhook_url, "âš ï¸ çˆ¬è™«æ•…éšœå‘Šè­¦", "\n".join(content_lines))
                triggered.append({"rule": rule["name"], "type": "failure", "errors": scrape_errors})

    return triggered
